{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep_7G754_PUX"
   },
   "source": [
    "# Accelerating PyTorch models with JAX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhSIPfbk07fv"
   },
   "source": [
    "Accelerate your Pytorch models by converting them to JAX for faster inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEoCDYyRsBLu"
   },
   "source": [
    "‚ö†Ô∏è If you are running this notebook in Colab, you will have to install `Ivy` and some dependencies manually. You can do so by running the cell below ‚¨áÔ∏è\n",
    "\n",
    "If you want to run the notebook locally but don't have Ivy installed just yet, you can check out the [Get Started section of the docs.](https://unify.ai/docs/ivy/overview/get_started.html)  \n",
    "\n",
    "Make sure you run this demo with GPU enabled!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "nnyOp6JusBLv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q ivy\n",
    "!pip install -q transformers\n",
    "!pip install -q dm-haiku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l39vDhft8F8X"
   },
   "source": [
    "Let's now import Ivy and the libraries we'll use in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "29c5UttUsK17"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import ivy\n",
    "ivy.set_default_device(\"gpu:0\")\n",
    "import torch\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import AutoModel, AutoFeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DUmTxOz8Q25"
   },
   "source": [
    "Now we can load a ResNet model and its corresponding feature extractor from Hugging Face transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Fl2RJ_KlsNy2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-02 19:23:15.980130: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-02 19:23:15.980177: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-02 19:23:15.980207: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-02 19:23:17.351203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "arch_name = \"ResNet\"\n",
    "checkpoint_name = \"microsoft/resnet-50\"\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(checkpoint_name)\n",
    "model = AutoModel.from_pretrained(checkpoint_name).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BseySf2g82kx"
   },
   "source": [
    "We will also need a sample image to pass during tracing, so let's use the feature extractor to get the corresponding torch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OK_mu3brssdT"
   },
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = feature_extractor(\n",
    "    images=image, return_tensors=\"pt\"\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_4af3mZ88Wl"
   },
   "source": [
    "And finally, let's transpile the model to haiku!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEBx4fwFvmC-",
    "outputId": "ef553432-e143-4248-c674-d0c0a6bf80db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:To preserve the tracer and transpiler caches across multiple machines, ensure that the relative path of your projects from the .ivy folder is consistent across all machines. You can do this by adding .ivy to your home folder and placing all projects in the same place relative to the home folder on all machines.\n",
      "WARNING:root:Native Numpy does not support GPU placement, consider using Jax instead\n",
      "/workspaces/ivy/ivy/utils/exceptions.py:390: UserWarning: The current backend: 'jax' does not support inplace updates natively. Ivy would quietly create new arrays when using inplace updates with this backend, leading to memory overhead (same applies for views). If you want to control your memory management, consider doing ivy.set_inplace_mode('strict') which should raise an error whenever an inplace update is attempted with this backend.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transpiled_graph = ivy.transpile(model, to=\"haiku\", kwargs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xe-vwz9v9Czh"
   },
   "source": [
    "After transpiling our model, we can see what's the improvement in runtime efficiency like. For this let's compile the original PyTorch model using `torch.compile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7mUKwqWnvx1Q"
   },
   "outputs": [],
   "source": [
    "inputs = feature_extractor(\n",
    "    images=image, return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "\n",
    "def _f(**kwargs):\n",
    "  return model(**kwargs)\n",
    "\n",
    "comp_model = torch.compile(_f)\n",
    "_ = comp_model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg1o9T-B9aIr"
   },
   "source": [
    "Let's now do the equivalent transformation in our new haiku model by using JAX just in time compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YQk3gbihv483"
   },
   "outputs": [],
   "source": [
    "inputs_jax = feature_extractor(\n",
    "    images=image, return_tensors=\"jax\"\n",
    ")\n",
    "\n",
    "import haiku as hk\n",
    "\n",
    "def _forward(**kwargs):\n",
    "  module = transpiled_graph()\n",
    "  return module(**kwargs).last_hidden_state\n",
    "\n",
    "rng_key = jax.random.PRNGKey(42)\n",
    "jax_forward = hk.transform(_forward)\n",
    "params = jax_forward.init(rng=rng_key, **inputs_jax)\n",
    "jit_apply = jax.jit(jax_forward.apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ulQ5z1n9SuR"
   },
   "source": [
    "Now that we have both models optimized, let's see how their runtime speeds compare to each other!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LOd86nDv0uW",
    "outputId": "513dcdfd-742b-4ef3-df3d-1c20699a616d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.63 ms ¬± 122 ¬µs per loop (mean ¬± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "_ = comp_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7r02dlwv6ce",
    "outputId": "441f11f0-7cb5-4aee-b5a5-f10934c6707d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18 ms ¬± 134 ¬µs per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "out = jit_apply(params, None, **inputs_jax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uR2BAWZC-hvh"
   },
   "source": [
    "As expected, we have made the model significantly faster with just one line of code, getting a ~2x increase in its execution speed! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTVG4pt807f0"
   },
   "source": [
    "Finally, as a sanity check, let's load a different image and make sure that the results are the same in both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QpxvZOwm07f0",
    "outputId": "ccb69550-4606-4ca0-abb1-b84d8c197c08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://images.cocodataset.org/train2017/000000283921.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs = feature_extractor(\n",
    "    images=image, return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "inputs_jax = feature_extractor(\n",
    "    images=image, return_tensors=\"jax\"\n",
    ")\n",
    "out_torch = comp_model(**inputs)\n",
    "out_jax = jit_apply(params, None, **inputs_jax)\n",
    "\n",
    "np.allclose(out_torch.last_hidden_state.detach().cpu().numpy(), out_jax, atol=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mS5d3iIZ07f0"
   },
   "source": [
    "That's pretty much it! The results from both models are the same, but we have achieved a solid speed up by using Ivy's transpiler to convert the model to JAX!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
