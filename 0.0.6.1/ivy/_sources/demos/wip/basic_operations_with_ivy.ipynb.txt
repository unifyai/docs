{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Basic Operations with Ivy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jwEdXSBcXCGy"
      },
      "source": [
        "## Installs üíæ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ18Kd5F3uKe"
      },
      "outputs": [],
      "source": [
        "!pip install ivy\n",
        "!pip install torch\n",
        "!pip install tensorflow\n",
        "!pip install jax\n",
        "!pip install dm-haiku\n",
        "!pip install numpy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sekVdg-DW537"
      },
      "source": [
        "## Imports üõÉ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6A4cYE9wSV2X"
      },
      "outputs": [],
      "source": [
        "import ivy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GnltH92YDz3h"
      },
      "source": [
        "## Ivy as a Unified ML Framework üîÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ylfk5mPUD5yZ"
      },
      "source": [
        "Ivy is a unified machine learning framework that aims to provide a single interface for working with various machine learning libraries, such as Numpy, TensorFlow, PyTorch, and Jax. With Ivy, you can use the same code to build and train machine learning models, regardless of the underlying library being used. All you have to do is to change one line of code üòâ"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NTIpyQgJEKK9"
      },
      "source": [
        "### Change frameworks by one line of code ‚òù"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IEcpaumIBEh"
      },
      "source": [
        "With Ivy, you can define your data and operations just once and easily switch between different frameworks. To do this, simply write your operations in Ivy and use the `ivy.set_framework()` function to change the underlying framework.\n",
        "\n",
        "P.S. there are some more advanced ways of handling backend frameworks in Ivy, so check it out in our [Deep Dive](https://lets-unify.ai/ivy/deep_dive/backend_setting.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCzvaftsG8lc"
      },
      "source": [
        "### No need to worry about data types üé®"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7pGFgOiF127"
      },
      "source": [
        "Firstly, let's set the backend to Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "El_nUM__D2Ag"
      },
      "outputs": [],
      "source": [
        "ivy.set_framework('tensorflow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9szEYZqH3C-",
        "outputId": "0eef18b2-4a56-4410-c58b-00e4f0065451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "x = ivy.array([1, 2, 3])\n",
        "y = ivy.array([4, 5, 6])\n",
        "print((type(ivy.to_native(x))))\n",
        "print(ivy.stack((x, y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlJJ9T0WVa5-"
      },
      "source": [
        "Now let's try exactly the same code, but change the used backend framework to Pytorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "K-p7iquzEVpu"
      },
      "outputs": [],
      "source": [
        "ivy.set_framework('torch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNLIuLTuH5Fs",
        "outputId": "b6b602ef-a81c-48a7-ada3-a3b2d5efb353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "x = ivy.array([1, 2, 3])\n",
        "y = ivy.array([4, 5, 6])\n",
        "print((type(ivy.to_native(x))))\n",
        "print(ivy.stack((x, y)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKYT7C95GAel"
      },
      "source": [
        "You can see that defined Ivy arrays have either tf.Tensor or torch.Tensor types underneath it without any need to worry about their types."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RbFMeUEHlpk"
      },
      "source": [
        "### No need to worry about framework differences üí±"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-2Q-B31Ki3J"
      },
      "source": [
        "By saying that framework can be changed by just one line of code, we really mean it üôÇ! By using Ivy as an ML framework, you do not need to worry about different function namings in different frameworks.\n",
        "\n",
        "Take a clip by value operator as an example. It performs the same operation across frameworks, but has different name and argument names.\n",
        "Numpy:\n",
        "```\n",
        "np.clip(a, a_min, a_max, out=None)\n",
        "```\n",
        "Tensforflow:\n",
        "```\n",
        "tf.clip_by_value(t, clip_value_min, clip_value_max, name=None)\n",
        "```\n",
        "Pytorch:\n",
        "```\n",
        "torch.clamp(input, min=None, max=None, *, out=None)\n",
        "```\n",
        "Jax:\n",
        "```\n",
        "jax.numpy.clip(a, a_min=None, a_max=None, out=None)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH__ljNOMW-K"
      },
      "source": [
        "Here are some examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VwJqENZNY73",
        "outputId": "2f971378-c049-4180-9267-c33899a20e15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[-1. -1.  0.]\n",
            " [ 0.  1.  1.]], shape=(2, 3), dtype=float32)\n",
            "[[-1. -1.  0.]\n",
            " [ 0.  1.  1.]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "t = tf.constant([[-10., -1., 0.], [0., 2., 10.]])\n",
        "print(tf.clip_by_value(t, clip_value_min=-1, clip_value_max=1))\n",
        "\n",
        "import numpy as np\n",
        "n = np.array([[-10., -1., 0.], [0., 2., 10.]])\n",
        "print(np.clip(n, a_min=-1, a_max=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBO1hLbJOExx"
      },
      "source": [
        "Ivy allows you not to worry about such things. Now let's do the same solely in Ivy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQp5ZoX5N1Ut",
        "outputId": "fa760212-8e48-41a8-d7c3-1227b90e049d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[-1., -1.,  0.],\n",
              "       [ 0.,  1.,  1.]])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ivy.set_framework('numpy')\n",
        "i = ivy.array([[-10., -1., 0.], [0., 2., 10.]])\n",
        "ivy.clip(i, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0q5urHVN_8S",
        "outputId": "5aa4fc74-18b0-4d3a-fbed-d5509b81ecb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1., -1.,  0.],\n",
              "        [ 0.,  1.,  1.]])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ivy.set_framework('torch')\n",
        "i = ivy.array([[-10., -1., 0.], [0., 2., 10.]])\n",
        "ivy.clip(i, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsAIGbAPOA8s",
        "outputId": "453c5e04-e953-4d8b-be80-3c2103359d3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
              "array([[-1., -1.,  0.],\n",
              "       [ 0.,  1.,  1.]], dtype=float32)>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ivy.set_framework('tensorflow')\n",
        "i = ivy.array([[-10., -1., 0.], [0., 2., 10.]])\n",
        "ivy.clip(i, -1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igPjvrWzJzfO",
        "outputId": "87d6ddc8-7335-46c5-daff-e1aba3475b20"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DeviceArray([[-1., -1.,  0.],\n",
              "             [ 0.,  1.,  1.]], dtype=float32)"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ivy.set_framework('jax')\n",
        "i = ivy.array([[-10., -1., 0.], [0., 2., 10.]])\n",
        "ivy.clip(i, -1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HWBBfT7QC31"
      },
      "source": [
        "As you see, the only line that changed here is `ivy.set_framework()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhzPEccDUVyA"
      },
      "source": [
        "### Unifying them all! üç≤"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48au6HsNVE6n"
      },
      "source": [
        "Finally, functions defined in Ivy are framework agnostic.\n",
        "In the example below we show how Ivy's concatenation function is compatible with tensors from different frameworks. This is the same for all Ivy functions. They can accept tensors from any framework and return the correct result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvXeZfEYDIDY"
      },
      "outputs": [],
      "source": [
        "import jax.numpy as jnp\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "import ivy\n",
        "\n",
        "jax_concatted   = ivy.concat((jnp.ones((1,)), jnp.ones((1,))), -1)\n",
        "tf_concatted    = ivy.concat((tf.ones((1,)), tf.ones((1,))), -1)\n",
        "np_concatted    = ivy.concat((np.ones((1,)), np.ones((1,))), -1)\n",
        "torch_concatted = ivy.concat((torch.ones((1,)), torch.ones((1,))), -1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1cq94A-93oB5"
      },
      "source": [
        "## Ivy as a standalone ML framework üåÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDwksucuEhvJ"
      },
      "source": [
        "Finally, let's train a simple two layer network using Ivy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj6Csk31MbWn"
      },
      "source": [
        "### Set Backend Framework\n",
        "\n",
        "You can change the framework to any of the following: `torch`, `tensforflow`, or `jax`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "OpAjb2zF3uuS"
      },
      "outputs": [],
      "source": [
        "ivy.set_framework('torch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwHQkTsTMYoP"
      },
      "source": [
        "### Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "W1e0JcWJ3xTq"
      },
      "outputs": [],
      "source": [
        "class MyModel(ivy.Module):\n",
        "    def __init__(self):\n",
        "        self.linear0 = ivy.Linear(3, 64)\n",
        "        self.linear1 = ivy.Linear(64, 1)\n",
        "        ivy.Module.__init__(self)\n",
        "\n",
        "    def _forward(self, x):\n",
        "        x = ivy.relu(self.linear0(x))\n",
        "        return ivy.sigmoid(self.linear1(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmWPJdcPMV5N"
      },
      "source": [
        "### Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "tTHRs0yY32Ft"
      },
      "outputs": [],
      "source": [
        "model = MyModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbcA8UWLMTnO"
      },
      "source": [
        "### Create Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "-whv0er432ZJ"
      },
      "outputs": [],
      "source": [
        "optimizer = ivy.Adam(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2fyFXyJMMMU"
      },
      "source": [
        "### Input and Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "B1vjp4vU34DQ"
      },
      "outputs": [],
      "source": [
        "x_in = ivy.array([1., 2., 3.])\n",
        "target = ivy.array([0.])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0SmFoAQMIyD"
      },
      "source": [
        "### Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "-iXLY5Rw35b0"
      },
      "outputs": [],
      "source": [
        "def loss_fn(v):\n",
        "    out = model(x_in, v=v)\n",
        "    return ivy.reduce_mean((out - target)**2)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7SspxMAMFjU"
      },
      "source": [
        "### Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT8GDPo036bL",
        "outputId": "c6866b31-2109-43d1-91c5-235c04048875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 0 loss 0.49040043354034424\n",
            "step 1 loss 0.48975786566734314\n",
            "step 2 loss 0.4892795979976654\n",
            "step 3 loss 0.48886892199516296\n",
            "step 4 loss 0.4884953498840332\n",
            "step 5 loss 0.4881443977355957\n",
            "step 6 loss 0.4878086447715759\n",
            "step 7 loss 0.48748287558555603\n",
            "step 8 loss 0.48716384172439575\n",
            "step 9 loss 0.48684927821159363\n",
            "step 10 loss 0.48653748631477356\n",
            "step 11 loss 0.48622724413871765\n",
            "step 12 loss 0.4859171509742737\n",
            "step 13 loss 0.48560672998428345\n",
            "step 14 loss 0.48529526591300964\n",
            "step 15 loss 0.4849821627140045\n",
            "step 16 loss 0.48466697335243225\n",
            "step 17 loss 0.4843493402004242\n",
            "step 18 loss 0.4840289056301117\n",
            "step 19 loss 0.4837053418159485\n",
            "step 20 loss 0.4833785891532898\n",
            "step 21 loss 0.4830484390258789\n",
            "step 22 loss 0.48271444439888\n",
            "step 23 loss 0.48237672448158264\n",
            "step 24 loss 0.48203518986701965\n",
            "step 25 loss 0.48168954253196716\n",
            "step 26 loss 0.4813397228717804\n",
            "step 27 loss 0.4809857904911041\n",
            "step 28 loss 0.48062753677368164\n",
            "step 29 loss 0.48026490211486816\n",
            "step 30 loss 0.479898065328598\n",
            "step 31 loss 0.47952669858932495\n",
            "step 32 loss 0.4791509211063385\n",
            "step 33 loss 0.4787706732749939\n",
            "step 34 loss 0.47838595509529114\n",
            "step 35 loss 0.4779967665672302\n",
            "step 36 loss 0.47760307788848877\n",
            "step 37 loss 0.4772048890590668\n",
            "step 38 loss 0.47680220007896423\n",
            "step 39 loss 0.47639501094818115\n",
            "step 40 loss 0.47598329186439514\n",
            "step 41 loss 0.4755673110485077\n",
            "step 42 loss 0.4751465618610382\n",
            "step 43 loss 0.4747215211391449\n",
            "step 44 loss 0.4742920398712158\n",
            "step 45 loss 0.47385817766189575\n",
            "step 46 loss 0.47341999411582947\n",
            "step 47 loss 0.47297725081443787\n",
            "step 48 loss 0.4725303053855896\n",
            "step 49 loss 0.47207894921302795\n",
            "step 50 loss 0.47162333130836487\n",
            "step 51 loss 0.47116345167160034\n",
            "step 52 loss 0.470699280500412\n",
            "step 53 loss 0.47023090720176697\n",
            "step 54 loss 0.4697583019733429\n",
            "step 55 loss 0.46928152441978455\n",
            "step 56 loss 0.46880054473876953\n",
            "step 57 loss 0.4683155119419098\n",
            "step 58 loss 0.4678264260292053\n",
            "step 59 loss 0.46733325719833374\n",
            "step 60 loss 0.46683603525161743\n",
            "step 61 loss 0.4663347601890564\n",
            "step 62 loss 0.4658295214176178\n",
            "step 63 loss 0.465320348739624\n",
            "step 64 loss 0.4648073613643646\n",
            "step 65 loss 0.46429020166397095\n",
            "step 66 loss 0.4637692868709564\n",
            "step 67 loss 0.46324464678764343\n",
            "step 68 loss 0.4627160429954529\n",
            "step 69 loss 0.4621836841106415\n",
            "step 70 loss 0.4616474211215973\n",
            "step 71 loss 0.46110764145851135\n",
            "step 72 loss 0.460563987493515\n",
            "step 73 loss 0.4600166976451874\n",
            "step 74 loss 0.45946577191352844\n",
            "step 75 loss 0.45891112089157104\n",
            "step 76 loss 0.45835286378860474\n",
            "step 77 loss 0.4577910006046295\n",
            "step 78 loss 0.45722562074661255\n",
            "step 79 loss 0.45665669441223145\n",
            "step 80 loss 0.4560841917991638\n",
            "step 81 loss 0.4555082619190216\n",
            "step 82 loss 0.45492875576019287\n",
            "step 83 loss 0.45434585213661194\n",
            "step 84 loss 0.45375964045524597\n",
            "step 85 loss 0.4531698524951935\n",
            "step 86 loss 0.4525766670703888\n",
            "step 87 loss 0.45198020339012146\n",
            "step 88 loss 0.4513803720474243\n",
            "step 89 loss 0.4507772624492645\n",
            "step 90 loss 0.4501707851886749\n",
            "step 91 loss 0.4495610296726227\n",
            "step 92 loss 0.4489481747150421\n",
            "step 93 loss 0.44833192229270935\n",
            "step 94 loss 0.4477125108242035\n",
            "step 95 loss 0.44708991050720215\n",
            "step 96 loss 0.44646409153938293\n",
            "step 97 loss 0.44583529233932495\n",
            "step 98 loss 0.4452032148838043\n",
            "step 99 loss 0.44456806778907776\n",
            "Finished training!\n"
          ]
        }
      ],
      "source": [
        "for step in range(100):\n",
        "    loss, grads = ivy.execute_with_gradients(loss_fn, model.v)\n",
        "    model.v = optimizer.step(model.v, grads)\n",
        "    print('step {} loss {}'.format(step, ivy.to_numpy(loss).item()))\n",
        "\n",
        "print('Finished training!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23kF-OzC36ul",
        "outputId": "5d12ecae-b557-442b-814e-9403f9c7ecec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.4439, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_fn(model.v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9R4S3JLQGaQ"
      },
      "source": [
        "We hope that this short demo gives you a better understanding of basic Ivy functionality and got your interest in learning more about Ivy!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
