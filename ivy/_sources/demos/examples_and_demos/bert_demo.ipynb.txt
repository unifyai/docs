{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Em2lO-yK0qbf"
      },
      "source": [
        "# Ivy Bert Demo\n",
        "--------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SrZvCT4QnBW"
      },
      "source": [
        "In this demo, we show how a [Bidirectional Encoder From Transformers (Bert)](https://pytorch.org/hub/huggingface_pytorch-transformers/) model written in Ivy native code  used for **Sequence Classification** and **MLM**, and integrated with all three of the major ML frameworks: **PyTorch**, **TensorFlow** and **JAX**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UebEZHTXwGkd"
      },
      "source": [
        "**First of all**\n",
        "You first have to enable gpu support if you are in **Google Colab**\n",
        "\n",
        "Go to **Runtime** -> **Change runtime type** -> **Choose Gpu**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC8O9zdlqIx-"
      },
      "source": [
        "## Install the dependecies\n",
        "\n",
        "- ivy `ivy library`\n",
        "- haiku `Haiku framework for jax`\n",
        "- ivy_models `ivy models library`\n",
        "- transformers ` Transformers library to get the pretrained model`\n",
        "\n",
        "**If you have all of the libraries installed you can save some time and skip this cell if not you should run this cell and restart the notebook**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NrE1GA21w9J"
      },
      "outputs": [],
      "source": [
        "!pip install -q ivy\n",
        "!pip install -q dm-haiku\n",
        "\n",
        "!pip install git+https://github.com/mohame54/models.git\n",
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUf2i-Py7fvh"
      },
      "source": [
        "## Import the modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RkeXJSDQ6q0r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import ivy\n",
        "ivy.set_default_device(\"gpu:0\")\n",
        "import ivy_models\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import warnings\n",
        "import numpy as np\n",
        "warnings.filterwarnings(\"ignore\") # to ignore the warnings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUpgv-NA8O0E"
      },
      "source": [
        "## Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPDb_AFj8ql6"
      },
      "source": [
        "**load the pretrained Model and tokenizer**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s42i-ja8BKz"
      },
      "outputs": [],
      "source": [
        "bert_base = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "bert_base = bert_base.eval() # for inference and evaluation\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJhhb3bqsLGI",
        "outputId": "03aa7b50-9c72-478b-d308-a42c9f38d27c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[ 101, 1045, 2106, 1005, 1056, 2428, 2066, 2115, 4309, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Prepare some samples to test on\n",
        "\n",
        "texts = [\"i did't really like your tone.\"]\n",
        "inputs = bert_tokenizer(texts,\n",
        "                        padding='longest',\n",
        "                        return_tensors='pt',\n",
        "                        max_length=512)\n",
        "inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfKPlX7v8kwC"
      },
      "source": [
        "**We get the transformers Bert pooler outputs to compare it with ivy bert outputs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wYpUctVr8ijT"
      },
      "outputs": [],
      "source": [
        "# torch model inference\n",
        "with torch.no_grad():\n",
        "   bert_output = bert_base(**inputs).pooler_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf6z4-Pw8yx7"
      },
      "source": [
        "##Ivy model Inference with numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNzGh6qS6sJR"
      },
      "source": [
        "**First We import [the native ivy code for Bert](https://github.com/unifyai/models/blob/master/ivy_models/bert/bert.py)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRd8Vnqf84lm"
      },
      "outputs": [],
      "source": [
        "ivy.set_backend('numpy')\n",
        "ivy_bert = ivy_models.bert_base_uncased(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxNcbpmm-QGs"
      },
      "outputs": [],
      "source": [
        "ivy_inputs = {k:ivy.asarray(v.numpy()) for k, v in inputs.items()}\n",
        "ivy_bert.trace_graph(kwargs=ivy_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-7UV4a3D6GM"
      },
      "source": [
        "### Ivy inference with Sequence Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXdi3ljr-Zb2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "ivy_output = ivy_bert(**ivy_inputs)['pooler_output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAdWIRsg42r_",
        "outputId": "fea074cf-8dcd-4d28-8155-449f5eec8086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits shapes, Ivy: [1, 768], torch: [1, 768]\n",
            "logits are equal\n"
          ]
        }
      ],
      "source": [
        "print(f\"logits shapes, Ivy: {list(ivy_output.shape)}, torch: {list(bert_output.shape)}\")\n",
        "logits_close = np.allclose(ivy_output, bert_output.detach().numpy(),rtol=0.005,atol=0.005)\n",
        "if logits_close:\n",
        "  print(f\"logits are equal\")\n",
        "else:\n",
        "  print(f\"logits are not equal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJZKvyEWE1_G"
      },
      "source": [
        "## Ivy model inference with tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BgLhnshLEGCG"
      },
      "outputs": [],
      "source": [
        "ivy.set_backend('tensorflow')\n",
        "ivy_bert = ivy_models.bert_base_uncased(pretrained=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j234lUfR3rqn"
      },
      "source": [
        "**Let's compare the runtime before and after tracing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mfwOKgTT3lNQ",
        "outputId": "74cc4524-c4f7-472f-8915-b533b49201fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished in 89.43 secs\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "st = time.time()\n",
        "ivy_inputs = {k:ivy.asarray(v.numpy()) for k, v in inputs.items()}\n",
        "ivy_output = ivy_bert(**ivy_inputs)['pooler_output']\n",
        "fn = time.time()\n",
        "print(f\"Finished in {(fn - st):.2f} secs\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SPInB4K64z7Y",
        "outputId": "45c55df5-d673-418c-c5d9-bf2a259f0445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits shapes, Ivy: [1, 768], torch: [1, 768]\n",
            "logits are equal\n"
          ]
        }
      ],
      "source": [
        "print(f\"logits shapes, Ivy: {list(ivy_output.shape)}, torch: {list(bert_output.shape)}\")\n",
        "logits_close = np.allclose(ivy_output.numpy(), bert_output.detach().numpy(),rtol=0.005,atol=0.005)\n",
        "if logits_close:\n",
        "  print(f\"logits are equal\")\n",
        "else:\n",
        "  print(f\"logits are not equal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE5MBcpu8zX3"
      },
      "source": [
        "**Now we trace the model**\n",
        "\n",
        "We repeat the same procedure before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhubB0HrEJBD"
      },
      "outputs": [],
      "source": [
        "ivy_bert.trace_graph(kwargs=ivy_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JluVC5dr3itt",
        "outputId": "1d5228d5-84a7-4c8f-d513-df37ab69474b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Finished in 0.60 secs\n"
          ]
        }
      ],
      "source": [
        "st = time.time()\n",
        "ivy_output = ivy_bert(**ivy_inputs)['pooler_output']\n",
        "fn = time.time()\n",
        "print(f\"Finished in {(fn - st):.2f} secs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzGqZB0791br"
      },
      "source": [
        "**We can see that the big difference in inference runtime before and after tracing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZrkaPMs0PgU",
        "outputId": "d0b8bf23-19e8-4fe6-ad0d-f1d7e37243e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits shapes, Ivy: [1, 768], torch: [1, 768]\n",
            "logits are equal\n"
          ]
        }
      ],
      "source": [
        "print(f\"logits shapes, Ivy: {list(ivy_output.shape)}, torch: {list(bert_output.shape)}\")\n",
        "logits_close = np.allclose(ivy_output.numpy(), bert_output.detach().numpy(),rtol=0.005,atol=0.005)\n",
        "if logits_close:\n",
        "  print(f\"logits are equal\")\n",
        "else:\n",
        "  print(f\"logits are not equal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1II9BgCP-Ez-"
      },
      "source": [
        "## Ivy model inference with Jax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMVQ3qpR0S2c"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "jax.config.update('jax_enable_x64', True)\n",
        "ivy.set_backend(\"jax\")\n",
        "ivy_bert = ivy_models.bert_base_uncased(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JUJRf_6-ZoX"
      },
      "outputs": [],
      "source": [
        "ivy_inputs = {k:ivy.asarray(v.numpy()) for k, v in inputs.items()}\n",
        "ivy_bert.trace_graph(kwargs=ivy_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6__J6K0_Xk0",
        "outputId": "b50c73f7-ca80-4ba7-b0fd-6ec60f680f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits shapes, Ivy: [1, 768], torch: [1, 768]\n",
            "logits are equal\n"
          ]
        }
      ],
      "source": [
        "ivy_output = ivy_bert(**ivy_inputs)['pooler_output']\n",
        "print(f\"logits shapes, Ivy: {list(ivy_output.shape)}, torch: {list(bert_output.shape)}\")\n",
        "ref = jnp.array( bert_output.detach())\n",
        "logits_close = jnp.allclose(ivy_output, ref,rtol=0.005,atol=0.005)\n",
        "if logits_close:\n",
        "  print(f\"logits are equal\")\n",
        "else:\n",
        "  print(f\"logits are not equal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9cljIdjQ5jY"
      },
      "source": [
        "## Ivy model inference with torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVfSgxJbx4Gz"
      },
      "source": [
        "**Initialize the model also trace it for fast inference**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idmu-H-8Q7DT"
      },
      "outputs": [],
      "source": [
        "ivy.set_backend(\"torch\")\n",
        "ivy_bert = ivy_models.bert_base_uncased(pretrained=True)\n",
        "ivy_inputs = {k:ivy.asarray(v.numpy()) for k, v in inputs.items()}\n",
        "ivy_bert.trace_graph(kwargs=ivy_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FytEsjXox_MJ"
      },
      "source": [
        "**Check logits values and the shapes of logits as before**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIZ-pX4jRWTq",
        "outputId": "54aa59f0-6fc7-4c01-f41d-e7319c5e66ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logits shapes, Ivy: [1, 768], torch: [1, 768]\n",
            "logits are equal\n"
          ]
        }
      ],
      "source": [
        "ivy_output = ivy_bert(**ivy_inputs)['pooler_output']\n",
        "print(f\"logits shapes, Ivy: {list(ivy_output.shape)}, torch: {list(bert_output.shape)}\")\n",
        "ref = bert_output.detach()\n",
        "logits_close = torch.allclose(ivy_output, ref.cuda(),rtol=0.005,atol=0.005)\n",
        "if logits_close:\n",
        "  print(f\"logits are equal\")\n",
        "else:\n",
        "  print(f\"logits are not equal\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
