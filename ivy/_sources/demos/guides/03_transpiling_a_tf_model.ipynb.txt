{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "r0J-_CN43iFB"
      },
      "source": [
        "# Transpiling a Tensorflow model to build on top"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Eg7DGGmT4iuF"
      },
      "source": [
        "Transpile a ``keras`` model to ``torch`` and build a new model around it.\n",
        "\n",
        "‚ö†Ô∏è If you are running this notebook in Colab, you will have to install Ivy and some dependencies manually. You can do so by running the cell below ‚¨áÔ∏è\n",
        "\n",
        "If you want to run the notebook locally but don't have Ivy installed just yet, you can check out the [Get Started section of the docs.](https://unify.ai/docs/ivy/overview/get_started.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xACzHp10hdTX"
      },
      "outputs": [],
      "source": [
        "%pip install ivy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GQCDMTkx46Wm"
      },
      "source": [
        "In Transpile Any Model we have seen how to transpile a torch model, now let's do the same with a model from keras transpiling a model from Keras to Torch and building a classifier on top of the resulting module.\n",
        "\n",
        "As usual, let's start with the imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21E0BUCSl6iu"
      },
      "outputs": [],
      "source": [
        "import ivy\n",
        "import torch\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5-mJlrhz5SBi"
      },
      "source": [
        "Now, instead of building our own Keras model, we will get one directly from Keras.\n",
        "\n",
        "In this case, we are going to use a EfficientNet. We can download the pretrained weights with `weights=\"imagenet\"` and set `include_top=False` to only retrieve the feature extractor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v523P9hGqf-Y",
        "outputId": "7b1da773-d0cf-4c5e-d11f-73fff07b2178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b0_notop.h5\n",
            "24274472/24274472 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Get a pretrained keras model\n",
        "eff_encoder = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3)\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wYT50RFT5mQx"
      },
      "source": [
        "Now, we will transpile the EfficientNet feature extractor to PyTorch using `ivy.transpile` and passing a sample `tf.tensor` with noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fML1OGasqs1o"
      },
      "outputs": [],
      "source": [
        "# Transpile it into a torch.nn.Module with the corresponding parameters\n",
        "noise = tf.random.normal(shape=(1, 224, 224, 3))\n",
        "torch_eff_encoder = ivy.transpile(eff_encoder, to=\"torch\", args=(noise,))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "koZ4UL_N6NFW"
      },
      "source": [
        "To ensure that the transpilation has been correct, let's check with a new input in both frameworks. Keep in mind that all the functions called within torch_eff_encoder are now PyTorch functions üîÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OhKUmJemLkh",
        "outputId": "dd77938a-c983-4e78-f403-778e8e85a0ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "x = np.random.random(size=(1, 224, 224, 3)).astype(np.float32)\n",
        "output_tf = eff_encoder(tf.constant(x, dtype=tf.float32))\n",
        "output_torch = torch_eff_encoder(torch.tensor(x))\n",
        "print(np.allclose(output_tf , output_torch.detach().numpy(), rtol=1e-1))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "rqCjBz6k7Flv"
      },
      "source": [
        "Now, we can build or own classifier using the transpiled module as the feature extractor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95FCfYQPljsu"
      },
      "outputs": [],
      "source": [
        "class Classifier(torch.nn.Module):\n",
        "    def __init__(self, num_classes=20):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.encoder = torch_eff_encoder\n",
        "        self.fc = torch.nn.Linear(1280, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GC5J0wyH7MpK"
      },
      "source": [
        "And finally, we can use our new model! As we have mentioned in \"Learn the Basics\", the transpiled model is fully trainable in the target framework, so you can also fine-tune your transpiled modules or train them from the ground up! üìâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghSeZ655lrAG",
        "outputId": "84d8aa53-53ec-4d3f-d120-47d2b7950977"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'> torch.Size([1, 7, 7, 20])\n"
          ]
        }
      ],
      "source": [
        "model = Classifier()\n",
        "x = torch.randn(1, 224, 224, 3)\n",
        "ret = model(x)\n",
        "print(type(ret), ret.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Round Up"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1IJy4ayl7WUW"
      },
      "source": [
        "That's it! Now you are ready to transpile any TensorFlow model, layer or trainable module and integrate it within PyTorch, but let's keep exploring how we can convert trainable modules from (and to!) other frameworks ‚û°Ô∏è"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
