{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "file: \"unify_existing_code/1_the_basics/1_1_framework_selection.ipynb\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1.1: Framework Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The source and target frameworks for `ivy.unify`, `ivy.trace_graph` and `ivy.transpile` can be: (a) inferred from the arguments and/or inspection of the function, (b) specified globally or (c) specified locally. All examples in the [Building Blocks]() either infer the source and target frameworks or specify them globally (via `ivy.set_backend`). We'll explore these various options, and also explore which modes take priority. For these examples, all functions are called *eagerly*. Please go through the [Lazy vs Eager]() notebook if you haven't already."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::: {#colab-button}\n",
    "[![Open in Colab]({{< var remote_badge.colab >}})](https://colab.research.google.com/github/unifyai/demos/blob/main/{{< meta file >}})\n",
    "[![GitHub]({{< var remote_badge.github >}})](https://github.com/unifyai/demos/blob/main/{{< meta file >}})\n",
    ":::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Unify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Consider again this simple `torch` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ivy\n",
    "import torch\n",
    "\n",
    "def normalize(x, mean, std):\n",
    "    return torch.div(torch.sub(x, mean), std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's also create the dummy data as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy\n",
    "import numpy as np\n",
    "\n",
    "# create random numpy arrays for testing\n",
    "x = np.randon.uniform(size=10)\n",
    "mean = np.mean(x)\n",
    "std = np.std(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This time, let's assume that our target framework is `jax`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "\n",
    "x = jnp.array(x)\n",
    "mean = jnp.array(mean)\n",
    "std = jnp.array(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the example below, the *source* framework of `torch` is *inferred* from the *function* `normalize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = ivy.unify(normalize, args=(x, mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As mentioned in the [Unify]() notebook, `ivy.unify` is able to detect that the original `normalize` function is implemented in `torch` by using the `inspection` module. `ivy.unify` then converts the framework-specific `torch` implementation into a framework-agnostic Ivy implementation, which is compatible with all frameworks.\n",
    "\n",
    "For some functions, this would not be possible. Consider the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_via_operators(x, mean, std):\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There is no way to determine the source framework from this function via the `inspection` module. This code uses built-in operators only, which are compatible with all ML frameworks. You might therefore think \"this is already unified\", but that's not true. Every ML framework has its own unique rules for broadcasting shapes and data types for elementwise functions, which must all be taken into account when converting code to `ivy`.\n",
    "\n",
    "Rather than inferring the framework, the framework can be specified *locally* as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = ivy.unify(normalize_via_operators, args=(x, mean, std), from=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Note that in all of the examples above, the arguments are in fact `jax` arrays. During function tracing, the `jax` arrays are converted to `torch` tensors automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the example below, the *target* framework of `jax` is *inferred* from the *arguments*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_comp = ivy.trace_graph(norm, args=(x, mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "However, if the Ivy function `norm` was purely generative (not consuming any arrays in the input), then this would not be possible. In such cases, we could set the target framework globally like so. If the type of the arguments conflicts with the globally set backend, then an error will be thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ivy.set_backend(\"jax\")\n",
    "norm_comp = ivy.trace_graph(norm, args=(x, mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Finally, the target framework can be provided locally. This will override any globally set backend, but again the arguments must be of the correct type in order to avoid errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ivy.set_backend(\"tensorflow\") # a different global backend\n",
    "norm_comp = ivy.trace_graph(norm, args=(x, mean, std), to=\"jax\") # doesn't matter, jax specified locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Transpile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "All consideration for both `ivy.unify` and `ivy.trace_graph` are combined for `ivy.transpile`, which is effectively shorthand for the combination of these two functions (as explained in the [Transpile]() section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the example below, the *source* framework of `torch` is *inferred* from the *function* `normalize`, **and** the *target* framework of `jax` is *inferred* from the *arguments*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "norm = ivy.transpile(normalize, args=(x, mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the example below, the *source* framework is specified *locally* (would be necessary if transpiling `normalize_via_operators` for example) **and** the *target* framework of `jax` is *inferred* from the *arguments*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm = ivy.transpile(normalize, args=(x, mean, std), from=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In the example below, the *source* framework is specified *locally* **and** the *target* framework of `jax` is specified *globally*. This might be necessary if there are no array arguments for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ivy.set_backend(\"jax\")\n",
    "norm = ivy.transpile(normalize, args=(x, mean, std), from=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As with `ivy.trace_graph`, the target framework can be provided locally. This will override any globally set backend, but again the arguments must be of the correct type in order to avoid errors.\n",
    "\n",
    "In the example below, the *source* framework is specified *locally* **and** the *target* framework of `jax` is also specified *locally*. Again, this might be necessary if there are no array arguments for the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ivy.set_backend(\"tensorflow\") # a different global backend\n",
    "norm = ivy.transpile(normalize, args=(x, mean, std), from=\"torch\", to=\"jax\") # doesn't matter, jax specified locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Round Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "That's it, you now know the difference between inferring, locally specifying, and globally specifying source and target frameworks for `ivy.unify`, `ivy.trace_graph` and `ivy.transpile`! However, there are several other important topics to master before you're ready to unify ML code like a pro 🥷. Next, we'll be exploring how these three functions can all be called as function decorators!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
